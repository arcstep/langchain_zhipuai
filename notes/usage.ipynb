{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydantic==1.10.13\n",
    "# !pip install pydantic==2.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "\n",
    "llm = ChatZhipuAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 或者你想自己临时指定API_KEY\n",
    "import os\n",
    "llm = ChatZhipuAI(api_key=os.getenv('ZHIPUAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"你是什么模型？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='我' id='8581412140046234897'\n",
      "content='使用的' id='8581412140046234897'\n",
      "content='模型' id='8581412140046234897'\n",
      "content='是' id='8581412140046234897'\n",
      "content='清华大学' id='8581412140046234897'\n",
      "content=' K' id='8581412140046234897'\n",
      "content='EG' id='8581412140046234897'\n",
      "content=' 实' id='8581412140046234897'\n",
      "content='验' id='8581412140046234897'\n",
      "content='室' id='8581412140046234897'\n",
      "content='和' id='8581412140046234897'\n",
      "content='智' id='8581412140046234897'\n",
      "content='谱' id='8581412140046234897'\n",
      "content='AI' id='8581412140046234897'\n",
      "content='共同' id='8581412140046234897'\n",
      "content='训练' id='8581412140046234897'\n",
      "content='的' id='8581412140046234897'\n",
      "content=' GL' id='8581412140046234897'\n",
      "content='M' id='8581412140046234897'\n",
      "content=' 模' id='8581412140046234897'\n",
      "content='型' id='8581412140046234897'\n",
      "content='，' id='8581412140046234897'\n",
      "content='一种' id='8581412140046234897'\n",
      "content='基于' id='8581412140046234897'\n",
      "content=' Transformer' id='8581412140046234897'\n",
      "content=' 的' id='8581412140046234897'\n",
      "content='通用' id='8581412140046234897'\n",
      "content='预' id='8581412140046234897'\n",
      "content='训练' id='8581412140046234897'\n",
      "content='语言' id='8581412140046234897'\n",
      "content='模型' id='8581412140046234897'\n",
      "content='。' id='8581412140046234897'\n",
      "content='Transformer' id='8581412140046234897'\n",
      "content=' 模' id='8581412140046234897'\n",
      "content='型' id='8581412140046234897'\n",
      "content='是一种' id='8581412140046234897'\n",
      "content='基于' id='8581412140046234897'\n",
      "content='自' id='8581412140046234897'\n",
      "content='注意力' id='8581412140046234897'\n",
      "content='机制的' id='8581412140046234897'\n",
      "content='深度' id='8581412140046234897'\n",
      "content='神经网络' id='8581412140046234897'\n",
      "content='模型' id='8581412140046234897'\n",
      "content='，' id='8581412140046234897'\n",
      "content='经常' id='8581412140046234897'\n",
      "content='用于' id='8581412140046234897'\n",
      "content='处理' id='8581412140046234897'\n",
      "content='序列' id='8581412140046234897'\n",
      "content='数据' id='8581412140046234897'\n",
      "content='。\\n\\n我' id='8581412140046234897'\n",
      "content='可能' id='8581412140046234897'\n",
      "content='用到' id='8581412140046234897'\n",
      "content='最大的' id='8581412140046234897'\n",
      "content='模型' id='8581412140046234897'\n",
      "content='是' id='8581412140046234897'\n",
      "content=' GL' id='8581412140046234897'\n",
      "content='M' id='8581412140046234897'\n",
      "content='-' id='8581412140046234897'\n",
      "content='130' id='8581412140046234897'\n",
      "content='B' id='8581412140046234897'\n",
      "content='，' id='8581412140046234897'\n",
      "content='具有' id='8581412140046234897'\n",
      "content=' ' id='8581412140046234897'\n",
      "content='130' id='8581412140046234897'\n",
      "content='0' id='8581412140046234897'\n",
      "content=' 亿' id='8581412140046234897'\n",
      "content='参数' id='8581412140046234897'\n",
      "content='，' id='8581412140046234897'\n",
      "content='支持' id='8581412140046234897'\n",
      "content='中' id='8581412140046234897'\n",
      "content='英' id='8581412140046234897'\n",
      "content='双语' id='8581412140046234897'\n",
      "content='。' id='8581412140046234897'\n",
      "content='我' id='8581412140046234897'\n",
      "content='具体' id='8581412140046234897'\n",
      "content='使用的' id='8581412140046234897'\n",
      "content='模型' id='8581412140046234897'\n",
      "content='规模' id='8581412140046234897'\n",
      "content='视' id='8581412140046234897'\n",
      "content='应用' id='8581412140046234897'\n",
      "content='场景' id='8581412140046234897'\n",
      "content='可能会有' id='8581412140046234897'\n",
      "content='所' id='8581412140046234897'\n",
      "content='变化' id='8581412140046234897'\n",
      "content='。' id='8581412140046234897'\n",
      "content='' id='8581412140046234897'\n"
     ]
    }
   ],
   "source": [
    "for s in llm.stream(\"你是什么模型？\"):\n",
    "  print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='我' id='8581411006174795324'\n",
      "content='是一名' id='8581411006174795324'\n",
      "content='人工智能' id='8581411006174795324'\n",
      "content='助手' id='8581411006174795324'\n",
      "content='，' id='8581411006174795324'\n",
      "content='基于' id='8581411006174795324'\n",
      "content='语言' id='8581411006174795324'\n",
      "content='模型' id='8581411006174795324'\n",
      "content=' GL' id='8581411006174795324'\n",
      "content='M' id='8581411006174795324'\n",
      "content='2' id='8581411006174795324'\n",
      "content=' 开' id='8581411006174795324'\n",
      "content='发' id='8581411006174795324'\n",
      "content='而成' id='8581411006174795324'\n",
      "content='。' id='8581411006174795324'\n",
      "content='GL' id='8581411006174795324'\n",
      "content='M' id='8581411006174795324'\n",
      "content='2' id='8581411006174795324'\n",
      "content=' 是' id='8581411006174795324'\n",
      "content='一个' id='8581411006174795324'\n",
      "content='开源' id='8581411006174795324'\n",
      "content='的语言' id='8581411006174795324'\n",
      "content='模型' id='8581411006174795324'\n",
      "content='，' id='8581411006174795324'\n",
      "content='由' id='8581411006174795324'\n",
      "content='清华大学' id='8581411006174795324'\n",
      "content=' K' id='8581411006174795324'\n",
      "content='EG' id='8581411006174795324'\n",
      "content=' 实' id='8581411006174795324'\n",
      "content='验' id='8581411006174795324'\n",
      "content='室' id='8581411006174795324'\n",
      "content='和' id='8581411006174795324'\n",
      "content='智' id='8581411006174795324'\n",
      "content='谱' id='8581411006174795324'\n",
      "content=' AI' id='8581411006174795324'\n",
      "content=' 公司' id='8581411006174795324'\n",
      "content='于' id='8581411006174795324'\n",
      "content=' ' id='8581411006174795324'\n",
      "content='202' id='8581411006174795324'\n",
      "content='3' id='8581411006174795324'\n",
      "content=' 年' id='8581411006174795324'\n",
      "content='共同' id='8581411006174795324'\n",
      "content='训练' id='8581411006174795324'\n",
      "content='。' id='8581411006174795324'\n",
      "content='我的' id='8581411006174795324'\n",
      "content='任务是' id='8581411006174795324'\n",
      "content='针对' id='8581411006174795324'\n",
      "content='用户' id='8581411006174795324'\n",
      "content='的问题' id='8581411006174795324'\n",
      "content='和要求' id='8581411006174795324'\n",
      "content='提供' id='8581411006174795324'\n",
      "content='适当的' id='8581411006174795324'\n",
      "content='答复' id='8581411006174795324'\n",
      "content='和支持' id='8581411006174795324'\n",
      "content='。' id='8581411006174795324'\n",
      "content='' id='8581411006174795324'\n"
     ]
    }
   ],
   "source": [
    "async for s in llm.astream([{\"role\": \"user\", \"content\": \"你是什么模型？\"}]):\n",
    "  print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'),\n",
       " AIMessage(content='我是一名人工智能助手，基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型 GLM-130B 开发而成。我的任务是针对用户的问题和要求提供适当的答复和支持。'),\n",
       " AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'),\n",
       " AIMessage(content='我是一名人工智能助手，基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型 GLM2 开发而成。我的任务是针对用户的问题和要求提供适当的答复和支持。'),\n",
       " AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'),\n",
       " AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'),\n",
       " AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'),\n",
       " AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'),\n",
       " AIMessage(content='我是一个基于语言的人工智能模型，名为 ChatGLM，现在又名智谱清言。我是由清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型 GLM-130B 开发的，我的任务是针对用户的问题和要求提供适当的答复和支持。我可以通过对大量文本的分析和学习，来模拟人类的语言理解和生成能力，从而与人类进行自然语言交互。'),\n",
       " AIMessage(content='我是一个人工智能助手，基于语言模型 GLM2 开发而成。GLM2 是一个开源的语言模型，由清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练。我的任务是针对用户的问题和要求提供适当的答复和支持。'),\n",
       " AIMessage(content='我是一名人工智能助手，基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型 GLM2 开发而成。我的任务是针对用户的问题和要求提供适当的答复和支持。'),\n",
       " AIMessage(content='我是一名人工智能助手，基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型 GLM-130B 开发而成。我的任务是针对用户的问题和要求提供适当的答复和支持。'),\n",
       " AIMessage(content='我是一个人工智能助手，基于语言模型 GLM2 开发而成。GLM2 是一个开源的双语预训练模型，由清华大学 KEG 实验室和智谱 AI 公司于 2022 年共同训练。我的任务是针对用户的问题和要求提供适当的答复和支持。'),\n",
       " AIMessage(content='我是一名人工智能助手，基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型 GLM2 开发而成。我的任务是针对用户的问题和要求提供适当的答复和支持。')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.batch([\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools-Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"query\":\"langchain_chinese是啥？请查询本地资料回答。\"}', 'name': 'search'}, 'id': 'call_8561159719973067303', 'index': 0, 'type': 'function'}]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"查询 langchan 资料; args: query 类型为字符串，描述用户的问题.\"\"\"\n",
    "    return \"langchain_chinese 是一个为中国大模型优化的langchain模块\"\n",
    "\n",
    "llm.bind(tools=[convert_to_openai_tool(search)]).invoke(\"langchain_chinese是啥？请查询本地资料回答。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## web_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='哪部电影好看这个问题，其实很主观，取决于每个人的个人喜好。如果你喜欢喜剧电影，周星驰的作品绝对值得推荐。周星驰的电影以幽默风趣、情节生动、角色鲜明著称，深受广大观众的喜爱。\\n\\n从你提供的参考信息来看，周星驰的以下几部电影是非常经典且备受推崇的：\\n\\n1. 《赌圣》：这部电影让周星驰开始崭露头角，以其独特的喜剧风格和精彩表演获得了观众的喜爱。\\n2. 《逃学威龙》：一部结合了校园和喜剧元素的电影，周星驰的表演和剧情设计都颇受好评。\\n3. 《大话西游》：这部电影的经典程度不用多说，周星驰与朱茵等人的合作成为了许多人心中的经典爱情悲喜剧。\\n4. 《喜剧之王》：这部电影是对演艺圈的幽默讽刺，同时也是周星驰对自己演艺生涯的一种回顾和反思。\\n\\n如果你是周星驰电影的爱好者，以上几部都是不错的选择。另外，《食神》和《鹿鼎记》也是周星驰的高票房作品，其中不乏创新和幽默的元素，同样值得一看。\\n\\n总的来说，选择哪部电影“好看”，还是要看你个人的口味和当时的心情。周星驰的电影大多数都是轻松愉快的喜剧，适合在休闲放松时观看。')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_zhipu import convert_to_web_search_tool\n",
    "llm.bind(tools=[convert_to_web_search_tool(search_query=\"周星驰电影\")]).invoke(\"哪部电影好看？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='马冬梅住在楼上322房间。')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_zhipu import convert_to_retrieval_tool\n",
    "llm.bind(tools=[convert_to_retrieval_tool(knowledge_id=\"1772979648448397312\")]).invoke(\"你知道马冬梅住哪里吗？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用官方接口"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 智能体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, Tool, create_openai_tools_agent\n",
    "from langchain import hub\n",
    "\n",
    "tools = [search]\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "for chunk in agent_executor.stream({\"input\": \"langchain_chinese是什么？\"}):\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM-4V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='图中有一片蓝天白云，大海，岩石，以及右下角的树木。具体地，在图片右边海岸边有几块黑色的岩石，岩石上长着深绿色的树木，图片下方是蓝色的海面，海面上方是广阔的蓝天和白色的云朵。')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm4v = ChatZhipuAI(model=\"glm-4v\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"图里有什么\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\" : \"https://img1.baidu.com/it/u=1369931113,3388870256&fm=253&app=138&size=w931&n=0&f=JPEG&fmt=auto?sec=1703696400&t=f3028c7a1dca43a080aeb8239f09cc2f\"\n",
    "            }\n",
    "          }\n",
    "        ]),\n",
    "])\n",
    "\n",
    "(prompt|llm4v).invoke({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27, 91, 882, 91, 29]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "\n",
    "llm = ChatZhipuAI(allowed_special=set())\n",
    "llm.get_token_ids('<|user|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(text=\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-zhipu-Ddey8KS3-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
