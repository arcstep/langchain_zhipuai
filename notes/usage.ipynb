{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydantic==1.10.13\n",
    "# !pip install pydantic==2.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "llm = ChatZhipuAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 或者你想自己临时指定API_KEY\n",
    "import os\n",
    "llm = ChatZhipuAI(api_key=os.getenv('ZHIPUAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "{\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"message\":{\"content\":\"我是一名人工智能助手，基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型 GLM2 开发而成。我的任务是针对用户的问题和要求提供适当的答复和支持。\",\"role\":\"assistant\"}}],\"created\":1712660999,\"id\":\"8554700845073161003\",\"model\":\"glm-4\",\"request_id\":\"8554700845073161003\",\"usage\":{\"completion_tokens\":47,\"prompt_tokens\":9,\"total_tokens\":56}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我是一名人工智能助手，基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型 GLM2 开发而成。我的任务是针对用户的问题和要求提供适当的答复和支持。')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"你是什么模型？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '我是一个'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '基于'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '语言'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '的人工'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '智能'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '模型'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '，'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '名为'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' Chat'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'GL'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'M'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '，'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '现在'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '又名'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '智'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '谱'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '清'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '言'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '。'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '我是'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '由'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '清华大学'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' K'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'EG'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' 实'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '验'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '室'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '和'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '智'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '谱'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' AI'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' 公司'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '于'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' '}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '202'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '3'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' 年'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '共同'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '训练'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '的语言'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '模型'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' GL'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'M'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '-'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '130'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': 'B'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ' 开'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '发的'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '，'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '我的'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '任务是'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '针对'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '用户'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '的问题'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '和要求'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '提供'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '适当的'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '答复'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '和支持'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '。'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '我'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '可以通过'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '对'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '大量'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '文本'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '的分析'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '学习'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '，'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '从而'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '能够'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '理解'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '语言'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '并'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '生成'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '回答'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '，'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '我'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '可以在'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '各种'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '主题'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '上'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '提供'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '帮助'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '，'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '包括'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '但不'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '限于'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '科普'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '知识'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '、'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '日常'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '咨询'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '、'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '文学'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '创作'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '等等'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': '。'}}]}\n",
      "{'id': '8554704212327614639', 'created': 1712662630, 'model': 'glm-4', 'choices': [{'index': 0, 'finish_reason': 'stop', 'delta': {'role': 'assistant', 'content': ''}}], 'usage': {'prompt_tokens': 9, 'completion_tokens': 100, 'total_tokens': 109}}\n"
     ]
    }
   ],
   "source": [
    "for s in llm._ask_remote_sse([{\"role\": \"user\", \"content\": \"你是什么模型？\"}]):\n",
    "  print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='我' id='8554704177967850800'\n",
      "content='使用的' id='8554704177967850800'\n",
      "content='模型' id='8554704177967850800'\n",
      "content='是' id='8554704177967850800'\n",
      "content='清华大学' id='8554704177967850800'\n",
      "content=' K' id='8554704177967850800'\n",
      "content='EG' id='8554704177967850800'\n",
      "content=' 实' id='8554704177967850800'\n",
      "content='验' id='8554704177967850800'\n",
      "content='室' id='8554704177967850800'\n",
      "content='和' id='8554704177967850800'\n",
      "content='智' id='8554704177967850800'\n",
      "content='谱' id='8554704177967850800'\n",
      "content='AI' id='8554704177967850800'\n",
      "content='共同' id='8554704177967850800'\n",
      "content='训练' id='8554704177967850800'\n",
      "content='的' id='8554704177967850800'\n",
      "content=' GL' id='8554704177967850800'\n",
      "content='M' id='8554704177967850800'\n",
      "content=' 模' id='8554704177967850800'\n",
      "content='型' id='8554704177967850800'\n",
      "content='，' id='8554704177967850800'\n",
      "content='一种' id='8554704177967850800'\n",
      "content='基于' id='8554704177967850800'\n",
      "content=' Transformer' id='8554704177967850800'\n",
      "content=' 的' id='8554704177967850800'\n",
      "content='通用' id='8554704177967850800'\n",
      "content='预' id='8554704177967850800'\n",
      "content='训练' id='8554704177967850800'\n",
      "content='语言' id='8554704177967850800'\n",
      "content='模型' id='8554704177967850800'\n",
      "content='。' id='8554704177967850800'\n",
      "content='Transformer' id='8554704177967850800'\n",
      "content=' 模' id='8554704177967850800'\n",
      "content='型' id='8554704177967850800'\n",
      "content='是一种' id='8554704177967850800'\n",
      "content='基于' id='8554704177967850800'\n",
      "content='自' id='8554704177967850800'\n",
      "content='注意力' id='8554704177967850800'\n",
      "content='机制的' id='8554704177967850800'\n",
      "content='深度' id='8554704177967850800'\n",
      "content='神经网络' id='8554704177967850800'\n",
      "content='模型' id='8554704177967850800'\n",
      "content='，' id='8554704177967850800'\n",
      "content='经常' id='8554704177967850800'\n",
      "content='用于' id='8554704177967850800'\n",
      "content='处理' id='8554704177967850800'\n",
      "content='序列' id='8554704177967850800'\n",
      "content='数据' id='8554704177967850800'\n",
      "content='。\\n\\n我' id='8554704177967850800'\n",
      "content='可能' id='8554704177967850800'\n",
      "content='用到' id='8554704177967850800'\n",
      "content='最大的' id='8554704177967850800'\n",
      "content='模型' id='8554704177967850800'\n",
      "content='是' id='8554704177967850800'\n",
      "content=' GL' id='8554704177967850800'\n",
      "content='M' id='8554704177967850800'\n",
      "content='-' id='8554704177967850800'\n",
      "content='130' id='8554704177967850800'\n",
      "content='B' id='8554704177967850800'\n",
      "content='，' id='8554704177967850800'\n",
      "content='具有' id='8554704177967850800'\n",
      "content=' ' id='8554704177967850800'\n",
      "content='130' id='8554704177967850800'\n",
      "content='0' id='8554704177967850800'\n",
      "content=' 亿' id='8554704177967850800'\n",
      "content='参数' id='8554704177967850800'\n",
      "content='，' id='8554704177967850800'\n",
      "content='支持' id='8554704177967850800'\n",
      "content='中' id='8554704177967850800'\n",
      "content='英' id='8554704177967850800'\n",
      "content='双语' id='8554704177967850800'\n",
      "content='。' id='8554704177967850800'\n",
      "content='我' id='8554704177967850800'\n",
      "content='具体' id='8554704177967850800'\n",
      "content='使用的' id='8554704177967850800'\n",
      "content='模型' id='8554704177967850800'\n",
      "content='规模' id='8554704177967850800'\n",
      "content='视' id='8554704177967850800'\n",
      "content='应用' id='8554704177967850800'\n",
      "content='场景' id='8554704177967850800'\n",
      "content='可能会有' id='8554704177967850800'\n",
      "content='所' id='8554704177967850800'\n",
      "content='变化' id='8554704177967850800'\n",
      "content='。' id='8554704177967850800'\n",
      "content='' id='8554704177967850800'\n"
     ]
    }
   ],
   "source": [
    "for s in llm.stream([{\"role\": \"user\", \"content\": \"你是什么模型？\"}]):\n",
    "  print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='我' id='8554700776353628804'\n",
      "content='是一名' id='8554700776353628804'\n",
      "content='人工智能' id='8554700776353628804'\n",
      "content='助手' id='8554700776353628804'\n",
      "content='，' id='8554700776353628804'\n",
      "content='基于' id='8554700776353628804'\n",
      "content='清华大学' id='8554700776353628804'\n",
      "content=' K' id='8554700776353628804'\n",
      "content='EG' id='8554700776353628804'\n",
      "content=' 实' id='8554700776353628804'\n",
      "content='验' id='8554700776353628804'\n",
      "content='室' id='8554700776353628804'\n",
      "content='和' id='8554700776353628804'\n",
      "content='智' id='8554700776353628804'\n",
      "content='谱' id='8554700776353628804'\n",
      "content=' AI' id='8554700776353628804'\n",
      "content=' 公司' id='8554700776353628804'\n",
      "content='于' id='8554700776353628804'\n",
      "content=' ' id='8554700776353628804'\n",
      "content='202' id='8554700776353628804'\n",
      "content='3' id='8554700776353628804'\n",
      "content=' 年' id='8554700776353628804'\n",
      "content='共同' id='8554700776353628804'\n",
      "content='训练' id='8554700776353628804'\n",
      "content='的语言' id='8554700776353628804'\n",
      "content='模型' id='8554700776353628804'\n",
      "content=' GL' id='8554700776353628804'\n",
      "content='M' id='8554700776353628804'\n",
      "content='-' id='8554700776353628804'\n",
      "content='130' id='8554700776353628804'\n",
      "content='B' id='8554700776353628804'\n",
      "content=' 开' id='8554700776353628804'\n",
      "content='发' id='8554700776353628804'\n",
      "content='而成' id='8554700776353628804'\n",
      "content='。' id='8554700776353628804'\n",
      "content='我的' id='8554700776353628804'\n",
      "content='任务是' id='8554700776353628804'\n",
      "content='针对' id='8554700776353628804'\n",
      "content='用户' id='8554700776353628804'\n",
      "content='的问题' id='8554700776353628804'\n",
      "content='和要求' id='8554700776353628804'\n",
      "content='提供' id='8554700776353628804'\n",
      "content='适当的' id='8554700776353628804'\n",
      "content='答复' id='8554700776353628804'\n",
      "content='和支持' id='8554700776353628804'\n",
      "content='。' id='8554700776353628804'\n",
      "content='' id='8554700776353628804'\n"
     ]
    }
   ],
   "source": [
    "async for s in llm.astream([{\"role\": \"user\", \"content\": \"你是什么模型？\"}]):\n",
    "  print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'),\n",
       " AIMessage(content='我是一个基于语言的人工智能模型，名为 ChatGLM，现在又名智谱清言。我是由清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型 GLM-130B 开发的，我的任务是针对用户的问题和要求提供适当的答复和支持。'),\n",
       " AIMessage(content='我是一名人工智能助手，基于语言模型 GLM2 开发而成。GLM2 是一个开源的语言模型，由清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练。我的任务是针对用户的问题和要求提供适当的答复和支持。'),\n",
       " AIMessage(content='我是一名人工智能助手，基于语言模型 GLM2 开发而成。GLM2 是一个开源的语言模型，由清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练。我的任务是针对用户的问题和要求提供适当的答复和支持。'),\n",
       " AIMessage(content='我是一名人工智能助手，基于清华大学 KEG 实验室和智谱AI共同训练的 GLM-130B 模型。GLM-130B 是一个双语双向稠密模型，拥有 1300 亿个参数，是中国人工智能领域的重要突破之一。我的任务是针对用户的问题和要求提供适当的答复和支持。'),\n",
       " AIMessage(content='我是一个人工智能助手模型，基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型 GLM-130B 开发而成。我的任务是针对用户的问题和要求提供适当的答复和支持。'),\n",
       " AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'),\n",
       " AIMessage(content='我是一名人工智能助手，基于清华大学 KEG 实验室和智谱AI共同训练的 GLM-130B 模型。我的任务是针对用户的问题和要求提供适当的答复和支持。'),\n",
       " AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'),\n",
       " AIMessage(content='我是一名人工智能助手，基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型 GLM-130B 开发而成。我的任务是针对用户的问题和要求提供适当的答复和支持。'),\n",
       " AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'),\n",
       " AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'),\n",
       " AIMessage(content='我是一名人工智能助手，基于语言模型 GLM-130B 开发而成。GLM-130B 是一个双语双向稠密模型，拥有 1300 亿个参数，是中国人工智能领域的重要突破之一。我能够进行自然语言处理、文本生成、知识问答等多种任务，旨在为用户提供丰富多样、有帮助的回答。'),\n",
       " AIMessage(content='我是一个人工智能助手模型，基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型 GLM2 开发而成。我的任务是针对用户的问题和要求提供适当的答复和支持。')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.batch([\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\",\n",
    "    \"你是什么模型？\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools-Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"query\":\"langchain_chinese是啥？\"}', 'name': 'search'}, 'id': 'call_8554703971809402094', 'index': 0, 'type': 'function'}]})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"查询 langchan 资料; args: query 类型为字符串，描述用户的问题.\"\"\"\n",
    "    return \"langchain_chinese 是一个为中国大模型优化的langchain模块\"\n",
    "\n",
    "llm.bind(tools=[convert_to_openai_tool(search)]).invoke(\"langchain_chinese是啥？请查询本地资料回答。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## web_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='选择哪部电影好看，这很大程度上取决于个人的喜好和审美。从您提供的参考信息来看，周星驰的电影无疑是非常受欢迎的，并且对很多观众来说具有很高的观赏价值。\\n\\n如果您喜欢喜剧片，那么周星驰的作品如《赌侠》、《逃学威龙》、《大话西游》、《唐伯虎点秋香》和《功夫》等都是经典之作，它们不仅具有极高的娱乐性，同时也蕴含了深刻的文化元素和人文情怀。这些电影不仅让周星驰成为了华语喜剧界的巨星，也使他的一些配角和创意成为了人们心中难以忘怀的部分。\\n\\n对于现代观众，尤其是喜欢结合网络文化和传统电影艺术的观众，可能会对周星驰与小杨哥合作的电影充满期待。虽然具体的电影项目尚未提及，但这样的合作往往能够吸引不同年龄层次的观众，将经典的喜剧元素与当代网络流行文化相结合，可能会产生全新的视觉和感官体验。\\n\\n总之，选择哪部电影好看，建议可以根据以下几点来决定：\\n1. 您的个人喜好：喜欢哪种类型的电影，喜剧、动作、爱情还是科幻等。\\n2. 口碑评价：参考电影的评价和评分，通常高评分的电影更值得观看。\\n3. 导演和演员：是否有您欣赏的导演或演员参与制作。\\n4. 文化内涵：电影是否有深入的文化内涵和值得思考的主题。\\n\\n结合以上因素，周星驰的电影无疑是一个不错的选择，无论是他的旧作还是未来可能的合作新片，都值得期待和观看。')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_zhipu import convert_to_web_search_tool\n",
    "llm.bind(tools=[convert_to_web_search_tool(search_query=\"周星驰电影\")]).invoke(\"哪部电影好看？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='马冬梅住在楼上322房间。')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_zhipu import convert_to_retrieval_tool\n",
    "llm.bind(tools=[convert_to_retrieval_tool(knowledge_id=\"1772979648448397312\")]).invoke(\"你知道马冬梅住哪里吗？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatZhipuAI(client=<langchain_zhipu._client.ZhipuAI object at 0x10c437220>), kwargs={'tools': [{'type': 'function', 'function': {'name': 'search', 'description': 'search(query: str) -> str - 查询 langchan 资料; args: query 类型为字符串，描述用户的问题.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}}, 'required': ['query']}}}]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.bind(tools=[convert_to_openai_tool(search)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用官方接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_zhipu import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"search\",\n",
    "                \"description\": \"search(query: str) -> str - 查询 langchan 资料; args: query 类型为字符串，描述用户的问题.'\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"query\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(model='glm-4', created=1711538632, choices=[CompletionChoice(index=0, finish_reason='tool_calls', message=CompletionMessage(content=None, role='assistant', tool_calls=[CompletionMessageToolCall(id='call_8513538359539114557', function=Function(arguments='{\"query\":\"langchain是什么？\"}', name='search'), type='function')]))], request_id='8513538359539114557', id='8513538359539114557', usage=CompletionUsage(prompt_tokens=128, completion_tokens=16, total_tokens=144))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.chat.completions.create(\n",
    "    model=\"glm-4\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"langchain是什么？请帮我查询\"\n",
    "        }\n",
    "    ],\n",
    "    tools = tools,\n",
    "    tool_choice=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIInternalError",
     "evalue": "Error code: 500, with error text {\"error\":{\"code\":\"500\",\"message\":\"Internal Error\"}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIInternalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mglm-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlangchain是什么？\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/langchain_zhipuai/langchain_zhipu/api_resource/chat/completions.py:48\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, model, request_id, do_sample, stream, temperature, top_p, max_tokens, seed, messages, stop, sensitive_word_check, tools, tool_choice, extra_headers, disable_strict_validation, timeout)\u001b[0m\n\u001b[1;32m     46\u001b[0m     _cast_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m     47\u001b[0m     _stream_cls \u001b[38;5;241m=\u001b[39m StreamResponse[\u001b[38;5;28mobject\u001b[39m]\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequest_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdo_sample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msensitive_word_check\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msensitive_word_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_user_request_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_cast_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_stream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/langchain_zhipuai/langchain_zhipu/core/_http_client.py:290\u001b[0m, in \u001b[0;36mHttpClient.post\u001b[0;34m(self, path, body, cast_type, options, files, enable_stream, stream_cls)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    278\u001b[0m         path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m         stream_cls: \u001b[38;5;28mtype\u001b[39m[StreamResponse[Any]] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    286\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m StreamResponse:\n\u001b[1;32m    287\u001b[0m     opts \u001b[38;5;241m=\u001b[39m ClientRequestParam\u001b[38;5;241m.\u001b[39mconstruct(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mmake_httpx_files(files), url\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m    288\u001b[0m                                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_stream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_stream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/langchain_zhipuai/langchain_zhipu/core/_http_client.py:249\u001b[0m, in \u001b[0;36mHttpClient.request\u001b[0;34m(self, cast_type, params, enable_stream, stream_cls)\u001b[0m\n\u001b[1;32m    247\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# raise err\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[0;31mAPIInternalError\u001b[0m: Error code: 500, with error text {\"error\":{\"code\":\"500\",\"message\":\"Internal Error\"}}"
     ]
    }
   ],
   "source": [
    "client.chat.completions.create(\n",
    "    model=\"glm-4\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"langchain是什么？\"\n",
    "        }\n",
    "    ],\n",
    "    tools = tools,\n",
    "    tool_choice=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 智能体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchainhub\n",
      "  Using cached langchainhub-0.1.15-py3-none-any.whl.metadata (621 bytes)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/langchain-zhipu-Ddey8KS3-py3.9/lib/python3.9/site-packages (from langchainhub) (2.31.0)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/langchain-zhipu-Ddey8KS3-py3.9/lib/python3.9/site-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/langchain-zhipu-Ddey8KS3-py3.9/lib/python3.9/site-packages (from requests<3,>=2->langchainhub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/langchain-zhipu-Ddey8KS3-py3.9/lib/python3.9/site-packages (from requests<3,>=2->langchainhub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/langchain-zhipu-Ddey8KS3-py3.9/lib/python3.9/site-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n",
      "Using cached langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
      "Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: types-requests, langchainhub\n",
      "Successfully installed langchainhub-0.1.15 types-requests-2.31.0.20240406\n"
     ]
    }
   ],
   "source": [
    "!pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "{'actions': [OpenAIToolAgentAction(tool='search', tool_input={'query': 'langchain_chinese是什么？'}, log=\"\\nInvoking: `search` with `{'query': 'langchain_chinese是什么？'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_8554703971809402816', 'index': 0, 'type': 'function', 'function': {'name': 'search', 'arguments': '{\"query\":\"langchain_chinese是什么？\"}'}}]})], tool_call_id='call_8554703971809402816')], 'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_8554703971809402816', 'index': 0, 'type': 'function', 'function': {'name': 'search', 'arguments': '{\"query\":\"langchain_chinese是什么？\"}'}}]})]}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search` with `{'query': 'langchain_chinese是什么？'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mlangchain_chinese 是一个为中国大模型优化的langchain模块\u001b[0m{'steps': [AgentStep(action=OpenAIToolAgentAction(tool='search', tool_input={'query': 'langchain_chinese是什么？'}, log=\"\\nInvoking: `search` with `{'query': 'langchain_chinese是什么？'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_8554703971809402816', 'index': 0, 'type': 'function', 'function': {'name': 'search', 'arguments': '{\"query\":\"langchain_chinese是什么？\"}'}}]})], tool_call_id='call_8554703971809402816'), observation='langchain_chinese 是一个为中国大模型优化的langchain模块')], 'messages': [FunctionMessage(content='langchain_chinese 是一个为中国大模型优化的langchain模块', name='search')]}\n",
      "\u001b[32;1m\u001b[1;3m根据我的查询结果，langchain_chinese 是一个为中国大模型优化的 langchain 模块。如果您需要更多关于 langchain_chinese 的资料，我可以为您提供更详细的信息。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'output': '根据我的查询结果，langchain_chinese 是一个为中国大模型优化的 langchain 模块。如果您需要更多关于 langchain_chinese 的资料，我可以为您提供更详细的信息。', 'messages': [AIMessage(content='根据我的查询结果，langchain_chinese 是一个为中国大模型优化的 langchain 模块。如果您需要更多关于 langchain_chinese 的资料，我可以为您提供更详细的信息。')]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, Tool, create_openai_tools_agent\n",
    "from langchain import hub\n",
    "\n",
    "tools = [search]\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "for chunk in agent_executor.stream({\"input\": \"langchain_chinese是什么？\"}):\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM-4V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='图中有一片蓝天白云，大海，岩石，以及右下角的树木。具体地，在图片右边海岸边有几块黑色的岩石，岩石上长着深绿色的树木，远处是蓝色的大海，海上有些层层涟漪，图片上方是蓝色的天空，天空中有大片的白云。')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm4v = ChatZhipuAI(model=\"glm-4v\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"图里有什么\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\" : \"https://img1.baidu.com/it/u=1369931113,3388870256&fm=253&app=138&size=w931&n=0&f=JPEG&fmt=auto?sec=1703696400&t=f3028c7a1dca43a080aeb8239f09cc2f\"\n",
    "            }\n",
    "          }\n",
    "        ]),\n",
    "])\n",
    "\n",
    "(prompt|llm4v).invoke({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27, 91, 882, 91, 29]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "\n",
    "llm = ChatZhipuAI(allowed_special=set())\n",
    "llm.get_token_ids('<|user|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(text=\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-zhipu-Ddey8KS3-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
