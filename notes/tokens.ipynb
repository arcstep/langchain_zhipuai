{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "\n",
    "class CountTokenCallbackHandler(BaseCallbackHandler):\n",
    "\tdef on_llm_end(self, response, **kwargs):\n",
    "\t\tprint(\"-\"*20, \"Token统计\", \"-\"*20)\n",
    "\t\tprint(response)\n",
    "\t\tprint(\"-\"*20, \"--------\", \"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "llm_glm = ChatZhipuAI(callbacks=[CountTokenCallbackHandler()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**支持invoke的token统计：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Token统计 --------------------\n",
      "generations=[[ChatGeneration(text='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'))]] llm_output={'id': '8561159135857491414', 'created': 1712935750, 'token_usage': {'completion_tokens': 91, 'prompt_tokens': 9, 'total_tokens': 100}, 'model_name': 'glm-4'} run=None\n",
      "-------------------- -------- --------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_glm.invoke(\"你是什么模型？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**支持stream方法的token统计：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='我' id='8563693888117904819'\n",
      "content='使用的' id='8563693888117904819'\n",
      "content='模型' id='8563693888117904819'\n",
      "content='是' id='8563693888117904819'\n",
      "content='清华大学' id='8563693888117904819'\n",
      "content=' K' id='8563693888117904819'\n",
      "content='EG' id='8563693888117904819'\n",
      "content=' 实' id='8563693888117904819'\n",
      "content='验' id='8563693888117904819'\n",
      "content='室' id='8563693888117904819'\n",
      "content='和' id='8563693888117904819'\n",
      "content='智' id='8563693888117904819'\n",
      "content='谱' id='8563693888117904819'\n",
      "content='AI' id='8563693888117904819'\n",
      "content='共同' id='8563693888117904819'\n",
      "content='训练' id='8563693888117904819'\n",
      "content='的' id='8563693888117904819'\n",
      "content=' GL' id='8563693888117904819'\n",
      "content='M' id='8563693888117904819'\n",
      "content=' 模' id='8563693888117904819'\n",
      "content='型' id='8563693888117904819'\n",
      "content='，' id='8563693888117904819'\n",
      "content='一种' id='8563693888117904819'\n",
      "content='基于' id='8563693888117904819'\n",
      "content=' Transformer' id='8563693888117904819'\n",
      "content=' 的' id='8563693888117904819'\n",
      "content='通用' id='8563693888117904819'\n",
      "content='预' id='8563693888117904819'\n",
      "content='训练' id='8563693888117904819'\n",
      "content='语言' id='8563693888117904819'\n",
      "content='模型' id='8563693888117904819'\n",
      "content='。' id='8563693888117904819'\n",
      "content='Transformer' id='8563693888117904819'\n",
      "content=' 模' id='8563693888117904819'\n",
      "content='型' id='8563693888117904819'\n",
      "content='是一种' id='8563693888117904819'\n",
      "content='基于' id='8563693888117904819'\n",
      "content='自' id='8563693888117904819'\n",
      "content='注意力' id='8563693888117904819'\n",
      "content='机制的' id='8563693888117904819'\n",
      "content='深度' id='8563693888117904819'\n",
      "content='神经网络' id='8563693888117904819'\n",
      "content='模型' id='8563693888117904819'\n",
      "content='，' id='8563693888117904819'\n",
      "content='经常' id='8563693888117904819'\n",
      "content='用于' id='8563693888117904819'\n",
      "content='处理' id='8563693888117904819'\n",
      "content='序列' id='8563693888117904819'\n",
      "content='数据' id='8563693888117904819'\n",
      "content='。\\n\\n我' id='8563693888117904819'\n",
      "content='可能' id='8563693888117904819'\n",
      "content='用到' id='8563693888117904819'\n",
      "content='最大的' id='8563693888117904819'\n",
      "content='模型' id='8563693888117904819'\n",
      "content='是' id='8563693888117904819'\n",
      "content=' GL' id='8563693888117904819'\n",
      "content='M' id='8563693888117904819'\n",
      "content='-' id='8563693888117904819'\n",
      "content='130' id='8563693888117904819'\n",
      "content='B' id='8563693888117904819'\n",
      "content='，' id='8563693888117904819'\n",
      "content='具有' id='8563693888117904819'\n",
      "content=' ' id='8563693888117904819'\n",
      "content='130' id='8563693888117904819'\n",
      "content='0' id='8563693888117904819'\n",
      "content=' 亿' id='8563693888117904819'\n",
      "content='参数' id='8563693888117904819'\n",
      "content='，' id='8563693888117904819'\n",
      "content='支持' id='8563693888117904819'\n",
      "content='中' id='8563693888117904819'\n",
      "content='英' id='8563693888117904819'\n",
      "content='双语' id='8563693888117904819'\n",
      "content='。' id='8563693888117904819'\n",
      "content='我' id='8563693888117904819'\n",
      "content='具体' id='8563693888117904819'\n",
      "content='使用的' id='8563693888117904819'\n",
      "content='模型' id='8563693888117904819'\n",
      "content='规模' id='8563693888117904819'\n",
      "content='视' id='8563693888117904819'\n",
      "content='应用' id='8563693888117904819'\n",
      "content='场景' id='8563693888117904819'\n",
      "content='可能会有' id='8563693888117904819'\n",
      "content='所' id='8563693888117904819'\n",
      "content='变化' id='8563693888117904819'\n",
      "content='。' id='8563693888117904819'\n",
      "content='' id='8563693888117904819'\n",
      "-------------------- Token统计 --------------------\n",
      "generations=[[ChatGenerationChunk(text='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。', generation_info={'model': 'glm-4', 'created': 1712936199, 'index': 0, 'finish_reason': 'stop', 'usage': {'prompt_tokens': 9, 'completion_tokens': 91, 'total_tokens': 100}}, message=AIMessageChunk(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'))]] llm_output=None run=None\n",
      "-------------------- -------- --------------------\n"
     ]
    }
   ],
   "source": [
    "for s in llm_glm.stream([{\"role\": \"user\", \"content\": \"你是什么模型？\"}]):\n",
    "  print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='我' id='8563446566721082204'\n",
      "content='使用的' id='8563446566721082204'\n",
      "content='模型' id='8563446566721082204'\n",
      "content='是' id='8563446566721082204'\n",
      "content='清华大学' id='8563446566721082204'\n",
      "content=' K' id='8563446566721082204'\n",
      "content='EG' id='8563446566721082204'\n",
      "content=' 实' id='8563446566721082204'\n",
      "content='验' id='8563446566721082204'\n",
      "content='室' id='8563446566721082204'\n",
      "content='和' id='8563446566721082204'\n",
      "content='智' id='8563446566721082204'\n",
      "content='谱' id='8563446566721082204'\n",
      "content='AI' id='8563446566721082204'\n",
      "content='共同' id='8563446566721082204'\n",
      "content='训练' id='8563446566721082204'\n",
      "content='的' id='8563446566721082204'\n",
      "content=' GL' id='8563446566721082204'\n",
      "content='M' id='8563446566721082204'\n",
      "content=' 模' id='8563446566721082204'\n",
      "content='型' id='8563446566721082204'\n",
      "content='，' id='8563446566721082204'\n",
      "content='一种' id='8563446566721082204'\n",
      "content='基于' id='8563446566721082204'\n",
      "content=' Transformer' id='8563446566721082204'\n",
      "content=' 的' id='8563446566721082204'\n",
      "content='通用' id='8563446566721082204'\n",
      "content='预' id='8563446566721082204'\n",
      "content='训练' id='8563446566721082204'\n",
      "content='语言' id='8563446566721082204'\n",
      "content='模型' id='8563446566721082204'\n",
      "content='。' id='8563446566721082204'\n",
      "content='Transformer' id='8563446566721082204'\n",
      "content=' 模' id='8563446566721082204'\n",
      "content='型' id='8563446566721082204'\n",
      "content='是一种' id='8563446566721082204'\n",
      "content='基于' id='8563446566721082204'\n",
      "content='自' id='8563446566721082204'\n",
      "content='注意力' id='8563446566721082204'\n",
      "content='机制的' id='8563446566721082204'\n",
      "content='深度' id='8563446566721082204'\n",
      "content='神经网络' id='8563446566721082204'\n",
      "content='模型' id='8563446566721082204'\n",
      "content='，' id='8563446566721082204'\n",
      "content='经常' id='8563446566721082204'\n",
      "content='用于' id='8563446566721082204'\n",
      "content='处理' id='8563446566721082204'\n",
      "content='序列' id='8563446566721082204'\n",
      "content='数据' id='8563446566721082204'\n",
      "content='。\\n\\n我' id='8563446566721082204'\n",
      "content='可能' id='8563446566721082204'\n",
      "content='用到' id='8563446566721082204'\n",
      "content='最大的' id='8563446566721082204'\n",
      "content='模型' id='8563446566721082204'\n",
      "content='是' id='8563446566721082204'\n",
      "content=' GL' id='8563446566721082204'\n",
      "content='M' id='8563446566721082204'\n",
      "content='-' id='8563446566721082204'\n",
      "content='130' id='8563446566721082204'\n",
      "content='B' id='8563446566721082204'\n",
      "content='，' id='8563446566721082204'\n",
      "content='具有' id='8563446566721082204'\n",
      "content=' ' id='8563446566721082204'\n",
      "content='130' id='8563446566721082204'\n",
      "content='0' id='8563446566721082204'\n",
      "content=' 亿' id='8563446566721082204'\n",
      "content='参数' id='8563446566721082204'\n",
      "content='，' id='8563446566721082204'\n",
      "content='支持' id='8563446566721082204'\n",
      "content='中' id='8563446566721082204'\n",
      "content='英' id='8563446566721082204'\n",
      "content='双语' id='8563446566721082204'\n",
      "content='。' id='8563446566721082204'\n",
      "content='我' id='8563446566721082204'\n",
      "content='具体' id='8563446566721082204'\n",
      "content='使用的' id='8563446566721082204'\n",
      "content='模型' id='8563446566721082204'\n",
      "content='规模' id='8563446566721082204'\n",
      "content='视' id='8563446566721082204'\n",
      "content='应用' id='8563446566721082204'\n",
      "content='场景' id='8563446566721082204'\n",
      "content='可能会有' id='8563446566721082204'\n",
      "content='所' id='8563446566721082204'\n",
      "content='变化' id='8563446566721082204'\n",
      "content='。' id='8563446566721082204'\n",
      "content='' id='8563446566721082204'\n",
      "-------------------- Token统计 --------------------\n",
      "generations=[[ChatGenerationChunk(text='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。', generation_info={'model': 'glm-4', 'created': 1712936231, 'index': 0, 'finish_reason': 'stop', 'usage': {'prompt_tokens': 9, 'completion_tokens': 91, 'total_tokens': 100}}, message=AIMessageChunk(content='我使用的模型是清华大学 KEG 实验室和智谱AI共同训练的 GLM 模型，一种基于 Transformer 的通用预训练语言模型。Transformer 模型是一种基于自注意力机制的深度神经网络模型，经常用于处理序列数据。\\n\\n我可能用到最大的模型是 GLM-130B，具有 1300 亿参数，支持中英双语。我具体使用的模型规模视应用场景可能会有所变化。'))]] llm_output=None run=None\n",
      "-------------------- -------- --------------------\n"
     ]
    }
   ],
   "source": [
    "async for s in llm_glm.astream([{\"role\": \"user\", \"content\": \"你是什么模型？\"}]):\n",
    "  print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatOpenAI的Token统计支持"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_gpt = ChatOpenAI(callbacks=[CountTokenCallbackHandler()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ChatOpenAI支持invoke方法的token统计：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Token统计 --------------------\n",
      "generations=[[ChatGeneration(text='我是一个基于人工智能技术的语言模型，用于回答用户提出的问题和进行对话。', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='我是一个基于人工智能技术的语言模型，用于回答用户提出的问题和进行对话。'))]] llm_output={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 15, 'total_tokens': 49}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None} run=None\n",
      "-------------------- -------- --------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我是一个基于人工智能技术的语言模型，用于回答用户提出的问题和进行对话。')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_gpt.invoke(\"你是什么模型？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**但并不支持stream方法的token统计：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=''\n",
      "content='我'\n",
      "content='是'\n",
      "content='一个'\n",
      "content='基'\n",
      "content='于'\n",
      "content='人'\n",
      "content='工'\n",
      "content='智'\n",
      "content='能'\n",
      "content='的'\n",
      "content='聊'\n",
      "content='天'\n",
      "content='机'\n",
      "content='器'\n",
      "content='人'\n",
      "content='模'\n",
      "content='型'\n",
      "content='。'\n",
      "content=''\n",
      "-------------------- Token统计 --------------------\n",
      "generations=[[ChatGenerationChunk(text='我是一个基于人工智能的聊天机器人模型。', generation_info={'finish_reason': 'stop'}, message=AIMessageChunk(content='我是一个基于人工智能的聊天机器人模型。'))]] llm_output=None run=None\n",
      "-------------------- -------- --------------------\n"
     ]
    }
   ],
   "source": [
    "for chunk in llm_gpt.stream(\"你是什么模型？\"):\n",
    "    print(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-zhipu-Ddey8KS3-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
